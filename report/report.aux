\relax 
\babel@aux{english}{}
\citation{AFrajtag12017}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Problem Statement}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Objectives}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Scope}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Significance}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Timeline}{3}}
\gtt@chartextrasize{0}{121.60583pt}
\citation{Ishizaka1972}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature review}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Sign Language}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Sign Language Alphabet. Retrieved from www.startASL.com\relax }}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sign_language}{{2.1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Deep Learning}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Typical deep learning model. Retrieved from www.medium.com\relax }}{6}}
\newlabel{fig:deep_learining}{{2.2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Activation Function}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Function:}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Sigmoid Function\relax }}{7}}
\newlabel{fig:sigmoid}{{2.3}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Tanh Function:}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Tanh Function\relax }}{8}}
\newlabel{fig:tanh}{{2.4}{8}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Function:}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces ReLU Function\relax }}{8}}
\newlabel{fig:relu}{{2.5}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Weights}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Bias}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Convolutional Neural Networks}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Feature Learning}{10}}
\@writefile{toc}{\contentsline {subsubsection}{CONV layer:}{10}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU layer:}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Pool Layer:}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Max pooling with 2x2 filter and stride = 2. Retrieved: Wikipedia\relax }}{11}}
\newlabel{fig:pool}{{2.6}{11}}
\citation{Bao2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Classification}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Fully Connected Layer(FC):}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Softmax:}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Complete CNN architecture. Retrieved: medium.com\relax }}{12}}
\newlabel{fig:c_cnn}{{2.7}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Previous works}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Architecture of the proposed deep CNN \relax }}{14}}
\newlabel{fig:tiny_architecture}{{2.8}{14}}
\citation{Rao2018}
\citation{Hussain2017}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Proposed Deep CNN architecture\relax }}{15}}
\newlabel{fig:selfie}{{2.9}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces VGG16 architecture. Retrieved from www.cs.toronto.edu\relax }}{16}}
\newlabel{fig:vgg16}{{2.10}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces AlexNet architecture. Retrieved from www.saagie.com\relax }}{16}}
\newlabel{fig:alexnet}{{2.11}{16}}
\citation{Pyo2016}
\citation{Devineau2018}
\@writefile{lof